{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No datasets available! Starting to generate.\n",
      "\n",
      "Run_Number_Run_Number___value               captorius3_acq_0_Channel_2_SSPALS_Y_[V]_t   captorius3_acq_0_Channel_2_SSPALS_Y_[V]_V   \n",
      "387124                                      [0.000000                                   [-0.0005                                    \n",
      "\n",
      "Loading 1 files from raw to bronze: 1it [00:05,  5.74s/it]\n",
      "Making Bronze to Silver.: 100%|██████████| 1/1 [00:00<00:00, 20.25it/s]\n",
      "Making Silver to Gold.: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Loading datasets: 1it [00:00, 31.98it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "first_run=387124\n",
    "last_run=387124\n",
    "\n",
    "command = f'c:/programowanie/python-analyses/venv/Scripts/python.exe c:/programowanie/python-analyses/ALPACA/applications/alpaca_to_database.py --first_run {first_run} --last_run {last_run}'\n",
    "\n",
    "        # Execute the command and capture the output\n",
    "\n",
    "result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "print(result.stdout.decode())\n",
    "print(result.stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SC56_coinc event_clock', '5TCCD acq_2 background_corrected img_with_roi', 'captorius3 acq_0 Channel_2_SSPALS Y_[V] t', 'captorius3 acq_0 Channel_2_SSPALS Y_[V] V']\n",
      "['SC56_coinc event_clock_shape', '5TCCD acq_2 background_corrected img_with_roi_shape', 'captorius3 acq_0 Channel_2_SSPALS Y_[V] t_shape', 'captorius3 acq_0 Channel_2_SSPALS Y_[V] V_shape']\n"
     ]
    }
   ],
   "source": [
    "first_run=387115\n",
    "last_run=387124\n",
    "df, columns_dic = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SC56_coinc event_clock                                      object\n",
       "SC56_coinc event_clock_shape                                object\n",
       "5TCCD acq_2 background_corrected img_with_roi               object\n",
       "5TCCD acq_2 background_corrected img_with_roi_shape         object\n",
       "1TCMOS acq_0 background_corrected roi signal_sum_in_roi    float64\n",
       "ELENA_Parameters H_offset_mm                               float64\n",
       "ELENA_Parameters V_offset_mm                               float64\n",
       "ELENA_Parameters H_angle_mrad                              float64\n",
       "ELENA_Parameters V_angle_mrad                              float64\n",
       "captorius3 acq_0 Channel_2_SSPALS Y_[V] t                   object\n",
       "captorius3 acq_0 Channel_2_SSPALS Y_[V] t_shape             object\n",
       "captorius3 acq_0 Channel_2_SSPALS Y_[V] V                   object\n",
       "captorius3 acq_0 Channel_2_SSPALS Y_[V] V_shape             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def serialize_df(df):\n",
    "    # Convert NumPy arrays with nan to lists\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == object and df[column].apply(type).eq(np.ndarray).any():\n",
    "            df[column] = df[column].apply(lambda arr: arr.tolist() if isinstance(arr, np.ndarray) else arr)\n",
    "\n",
    "    # Convert DataFrame to JSON string\n",
    "    json_str = df.to_json(orient='split')\n",
    "    return json_str\n",
    "\n",
    "def deserialize_df(json_str):\n",
    "    # Convert JSON string back to DataFrame\n",
    "    df = pd.read_json(json_str, orient='split')\n",
    "\n",
    "    # Convert lists back to NumPy arrays\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].apply(np.array)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import re\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "import psycopg2 as ps\n",
    "def initial_fetch_data():\n",
    "\n",
    "    engine=sqlalchemy.create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/alpaca\") # db instead of localhost for docker\n",
    "    with engine.begin() as conn:\n",
    "        query = sqlalchemy.text(\"\"\"SELECT * FROM alpaca\n",
    "                            \"\"\")\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    df.set_index('Run_Number Run_Number __value', inplace=True)\n",
    "\n",
    "    # need to convert arrays saved as bytes back to arrays\n",
    "    byte_columns = [column[:-6] for column in df.columns if column.endswith(\"_shape\") is True and df[column].dtype == object]\n",
    "    shape_columns = [f'{column}_shape' for column in byte_columns]\n",
    "    one_dimensional_columns=[]\n",
    "    two_dimensional_columns=[]\n",
    "\n",
    "    for shape_column in shape_columns:\n",
    "        column_name = shape_column[:-6]  # Extract the original column name\n",
    "        df[shape_column] = df[shape_column].apply(lambda x: tuple(map(int, re.findall(r'\\d+', x))) if pd.notnull(x) else None)  # Extract the shape values\n",
    "        shape_column_values = df[shape_column].dropna()[df[shape_column].dropna() != ()]\n",
    "        if not shape_column_values.empty:\n",
    "            length = len(shape_column_values.iloc[0])\n",
    "        else:\n",
    "            length = 0\n",
    "        if length == 1:\n",
    "            one_dimensional_columns.append(column_name)\n",
    "        elif length ==2:\n",
    "            two_dimensional_columns.append(column_name)\n",
    "\n",
    "    for column in byte_columns:\n",
    "        shape_column = f'{column}_shape'\n",
    "        df[column] = df.apply(lambda row: np.frombuffer(row[column]).reshape(row[shape_column]) if pd.notnull(row[column]) and pd.notnull(row[shape_column]) else None, axis=1)\n",
    "\n",
    "    numerical_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "    column_dic={'numerical_columns':numerical_columns,\n",
    "            'one_dimensional_columns': one_dimensional_columns,\n",
    "            'two_dimensional_columns': two_dimensional_columns}\n",
    "    \n",
    "    runs=df.index.values\n",
    "\n",
    "    return runs, column_dic\n",
    "\n",
    "\n",
    "def fetch_run(run_number):\n",
    "    engine=sqlalchemy.create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/alpaca\") # db instead of localhost for docker\n",
    "    with engine.begin() as conn:\n",
    "        if run_number:\n",
    "            query = sqlalchemy.text(\"\"\"SELECT * FROM alpaca\n",
    "                            WHERE \"Run_Number Run_Number __value\" = :run_number\n",
    "                            \"\"\")\n",
    "            df = pd.read_sql_query(query, conn, params={'run_number': run_number})\n",
    "\n",
    "    df.set_index('Run_Number Run_Number __value', inplace=True)\n",
    "\n",
    "    # need to convert arrays saved as bytes back to arrays\n",
    "    byte_columns = [column[:-6] for column in df.columns if column.endswith(\"_shape\") is True and df[column].dtype == object]\n",
    "    shape_columns = [f'{column}_shape' for column in byte_columns]\n",
    "\n",
    "    for shape_column in shape_columns:\n",
    "        df[shape_column] = df[shape_column].apply(lambda x: tuple(map(int, re.findall(r'\\d+', x))) if pd.notnull(x) else None)  # Extract the shape values\n",
    "\n",
    "    for column in byte_columns:\n",
    "        shape_column = f'{column}_shape'\n",
    "        df[column] = df.apply(lambda row: np.frombuffer(row[column]).reshape(row[shape_column]) if pd.notnull(row[column]) and pd.notnull(row[shape_column]) else None, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs, column_dic =initial_fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 392101, 'value': 392101},\n",
       " {'label': 378934, 'value': 378934},\n",
       " {'label': 378935, 'value': 378935},\n",
       " {'label': 378936, 'value': 378936},\n",
       " {'label': 378937, 'value': 378937},\n",
       " {'label': 378938, 'value': 378938},\n",
       " {'label': 378939, 'value': 378939},\n",
       " {'label': 373007, 'value': 373007},\n",
       " {'label': 387121, 'value': 387121},\n",
       " {'label': 387127, 'value': 387127},\n",
       " {'label': 387123, 'value': 387123},\n",
       " {'label': 387124, 'value': 387124},\n",
       " {'label': 387125, 'value': 387125},\n",
       " {'label': 387126, 'value': 387126},\n",
       " {'label': 387122, 'value': 387122},\n",
       " {'label': 387116, 'value': 387116},\n",
       " {'label': 387117, 'value': 387117}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_options = [{'label': number, 'value': number} for number in runs]\n",
    "run_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150.2693581, 150.278129 , 150.2885014, ..., 287.0376261,\n",
       "       287.0514474, 287.058995 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fetch_run(392101)\n",
    "df['SC56_coinc event_clock'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
